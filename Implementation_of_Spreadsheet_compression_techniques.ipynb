{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCmhJfMqmek3Ltr9SGahTp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DUrayev/RepostCleanerBot/blob/main/Implementation_of_Spreadsheet_compression_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. STRUCTURAL ANCHORS FOR EFFICIENT LAYOUT UNDERSTANDING\n",
        "\n"
      ],
      "metadata": {
        "id": "wWp5y7V2yJ3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This technique identifies heterogeneous rows/columns (structural anchors) and removes distant homogeneous areas that don't contribute to understanding spreadsheet layout"
      ],
      "metadata": {
        "id": "VzxDZNpUyOP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm implementation"
      ],
      "metadata": {
        "id": "ABjp49LvPDCk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZtiS02BFx_R6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def extract_structural_skeleton(df: pd.DataFrame, k: int = 1):\n",
        "    \"\"\"\n",
        "    Extract structural skeleton by identifying structural anchors (boundary rows/columns)\n",
        "    and keeping only k rows/columns around them, removing distant homogeneous regions.\n",
        "\n",
        "    This implementation compares rows WITH EACH OTHER to identify structural changes,\n",
        "    not the diversity within individual rows.\n",
        "    \"\"\"\n",
        "\n",
        "    def rows_are_similar(row1_idx, row2_idx, similarity_threshold=0.8):\n",
        "        \"\"\"Check if two rows are structurally similar\"\"\"\n",
        "        row1 = df.iloc[row1_idx].fillna('').astype(str)\n",
        "        row2 = df.iloc[row2_idx].fillna('').astype(str)\n",
        "\n",
        "        # Count how many positions have the same content\n",
        "        matches = sum(1 for a, b in zip(row1, row2) if a == b)\n",
        "        similarity = matches / len(row1)\n",
        "        return similarity >= similarity_threshold\n",
        "\n",
        "    def cols_are_similar(col1_idx, col2_idx, similarity_threshold=0.8):\n",
        "        \"\"\"Check if two columns are structurally similar\"\"\"\n",
        "        col1 = df.iloc[:, col1_idx].fillna('').astype(str)\n",
        "        col2 = df.iloc[:, col2_idx].fillna('').astype(str)\n",
        "\n",
        "        # Count how many positions have the same content\n",
        "        matches = sum(1 for a, b in zip(col1, col2) if a == b)\n",
        "        similarity = matches / len(col1)\n",
        "        return similarity >= similarity_threshold\n",
        "\n",
        "    # Find structural anchor rows (rows where structure changes)\n",
        "    row_anchors = set()\n",
        "    for i in range(df.shape[0]):\n",
        "        is_boundary = False\n",
        "\n",
        "        # Check if this row is different from adjacent rows (structural boundary)\n",
        "        if i == 0 or i == df.shape[0] - 1:\n",
        "            is_boundary = True  # First and last rows are always anchors\n",
        "        else:\n",
        "            # Check if current row is significantly different from neighbors\n",
        "            prev_similar = rows_are_similar(i-1, i)\n",
        "            next_similar = rows_are_similar(i, i+1) if i+1 < df.shape[0] else False\n",
        "\n",
        "            if not prev_similar and not next_similar:\n",
        "                is_boundary = True\n",
        "\n",
        "        if is_boundary:\n",
        "            row_anchors.add(i)\n",
        "\n",
        "    # Find structural anchor columns (columns where structure changes)\n",
        "    col_anchors = set()\n",
        "    for j in range(df.shape[1]):\n",
        "        is_boundary = False\n",
        "\n",
        "        # Check if this column is different from adjacent columns (structural boundary)\n",
        "        if j == 0 or j == df.shape[1] - 1:\n",
        "            is_boundary = True  # First and last columns are always anchors\n",
        "        else:\n",
        "            # Check if current column is significantly different from neighbors\n",
        "            prev_similar = cols_are_similar(j-1, j)\n",
        "            next_similar = cols_are_similar(j, j+1) if j+1 < df.shape[1] else False\n",
        "\n",
        "            if not prev_similar or not next_similar:\n",
        "                is_boundary = True\n",
        "\n",
        "        if is_boundary:\n",
        "            col_anchors.add(j)\n",
        "\n",
        "    # Expand anchors by k (keep k rows/columns around each structural anchor)\n",
        "    rows_to_keep = set()\n",
        "    for r in row_anchors:\n",
        "        rows_to_keep.update(range(max(0, r - k), min(df.shape[0], r + k + 1)))\n",
        "\n",
        "    cols_to_keep = set()\n",
        "    for c in col_anchors:\n",
        "        cols_to_keep.update(range(max(0, c - k), min(df.shape[1], c + k + 1)))\n",
        "\n",
        "    # Extract skeleton\n",
        "    return df.iloc[sorted(rows_to_keep), sorted(cols_to_keep)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example data"
      ],
      "metadata": {
        "id": "gQHBzuXEPIpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample DataFrame - realistic spreadsheet with truly homogeneous regions  \n",
        "This demonstrates the power of structural anchors by having low-information density areas"
      ],
      "metadata": {
        "id": "7owwUspzyonH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    # Table 1: Sales Report (rows 0-3) - Distinct structure\n",
        "    'A': ['Sales Report', 'Product', 'Laptop', 'Phone',\n",
        "          # Homogeneous region (rows 4-11) - Repeated similar rows\n",
        "          'Notes', 'Notes', 'Notes', 'Notes', 'Notes', 'Notes', 'Notes', 'Notes',\n",
        "          # Table 2: Employee Data (rows 12-15) - Different structure\n",
        "          'Employee List', 'Name', 'John Smith', 'Jane Doe',\n",
        "          # Another homogeneous region (rows 16-23) - Different repeated pattern\n",
        "          'Summary', 'Summary', 'Summary', 'Summary', 'Summary', 'Summary', 'Summary', 'Summary',\n",
        "          # Table 3: Financial Data (rows 24-27) - Third distinct structure\n",
        "          'Q4 Finances', 'Revenue', '$10000', '$15000'],\n",
        "\n",
        "    'B': ['Q4 2024', 'Units', '150', '200',\n",
        "          # Homogeneous region - Same pattern as column A\n",
        "          'Details', 'Details', 'Details', 'Details', 'Details', 'Details', 'Details', 'Details',\n",
        "          # Employee table - Different pattern\n",
        "          'Department', 'Engineering', 'Engineering', 'Marketing',\n",
        "          # Homogeneous region - Different repeated pattern\n",
        "          'Info', 'Info', 'Info', 'Info', 'Info', 'Info', 'Info', 'Info',\n",
        "          # Financial table - Third pattern\n",
        "          'Target', 'Actual', '$12000', '$14000'],\n",
        "\n",
        "    'C': ['Region', 'Price', '$1200', '$800',\n",
        "          # Homogeneous region - Similar to A and B pattern\n",
        "          'Extra', 'Extra', 'Extra', 'Extra', 'Extra', 'Extra', 'Extra', 'Extra',\n",
        "          # Employee table - Matches employee pattern\n",
        "          'Location', 'Seattle', 'Seattle', 'New York',\n",
        "          # Homogeneous region - Matches summary pattern\n",
        "          'More', 'More', 'More', 'More', 'More', 'More', 'More', 'More',\n",
        "          # Financial - Matches financial pattern\n",
        "          'Status', 'Goal Met', 'Yes', 'Yes'],\n",
        "\n",
        "    'D': ['North', 'Count', '5', '8',\n",
        "          # Homogeneous region - Similar repeated pattern\n",
        "          'Misc', 'Misc', 'Misc', 'Misc', 'Misc', 'Misc', 'Misc', 'Misc',\n",
        "          # Employee table - Matches employee pattern\n",
        "          'Building', 'A', 'A', 'B',\n",
        "          # Homogeneous region - Matches summary pattern\n",
        "          'End', 'End', 'End', 'End', 'End', 'End', 'End', 'End',\n",
        "          # Financial - Matches financial pattern\n",
        "          'Quarter', 'Q4', 'Complete', 'Complete'],\n",
        "}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "ncwSTXk6yhZ0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This spreadsheet contains multiple tables separated by homogeneous regions:\n",
        "- Rows 0-3: Sales table (different structure)\n",
        "- Rows 4-11: Homogeneous region (repeated 'Notes/Details/Extra/Misc' pattern)\n",
        "- Rows 12-15: Employee table (different structure)\n",
        "- Rows 16-23: Homogeneous region (repeated 'Summary/Info/More/End' pattern)\n",
        "- Rows 24-27: Financial table (different structure)\n",
        "\n",
        "The algorithm will identify where structure changes and keep 'k' rows around each boundary."
      ],
      "metadata": {
        "id": "d8gjLSQNy3Hz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original DataFrame:\n",
        "\n",
        "```\n",
        "                A            B         C         D\n",
        "0    Sales Report      Q4 2024    Region     North\n",
        "1         Product        Units     Price     Count\n",
        "2          Laptop          150     $1200         5\n",
        "3           Phone          200      $800         8\n",
        "4           Notes      Details     Extra      Misc\n",
        "5           Notes      Details     Extra      Misc\n",
        "6           Notes      Details     Extra      Misc\n",
        "7           Notes      Details     Extra      Misc\n",
        "8           Notes      Details     Extra      Misc\n",
        "9           Notes      Details     Extra      Misc\n",
        "10          Notes      Details     Extra      Misc\n",
        "11          Notes      Details     Extra      Misc\n",
        "12  Employee List   Department  Location  Building\n",
        "13           Name  Engineering   Seattle         A\n",
        "14     John Smith  Engineering   Seattle         A\n",
        "15       Jane Doe    Marketing  New York         B\n",
        "16        Summary         Info      More       End\n",
        "17        Summary         Info      More       End\n",
        "18        Summary         Info      More       End\n",
        "19        Summary         Info      More       End\n",
        "20        Summary         Info      More       End\n",
        "21        Summary         Info      More       End\n",
        "22        Summary         Info      More       End\n",
        "23        Summary         Info      More       End\n",
        "24    Q4 Finances       Target    Status   Quarter\n",
        "25        Revenue       Actual  Goal Met        Q4\n",
        "26         $10000       $12000       Yes  Complete\n",
        "27         $15000       $14000       Yes  Complete\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ke4_e_u2y8jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skeleton = extract_structural_skeleton(df, k=1)"
      ],
      "metadata": {
        "id": "ZwcGvWyGzLvf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display results with compression metrics"
      ],
      "metadata": {
        "id": "l64ipvb5zSFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(f\"\\nStructural Anchor Extraction Results:\")\n",
        "print(f\"  Original shape: {df.shape} ({df.shape[0] * df.shape[1]} cells)\")\n",
        "print(f\"  Skeleton shape: {skeleton.shape} ({skeleton.shape[0] * skeleton.shape[1]} cells)\")\n",
        "compression_ratio = (df.shape[0] * df.shape[1]) / (skeleton.shape[0] * skeleton.shape[1])\n",
        "print(f\"  Compression ratio: {compression_ratio:.2f}x\")\n",
        "print(f\"  Space saved: {((df.shape[0] * df.shape[1] - skeleton.shape[0] * skeleton.shape[1]) / (df.shape[0] * df.shape[1]) * 100):.1f}%\")\n",
        "print(\"\\nExtracted Structural Skeleton:\")\n",
        "print(skeleton)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QON50VpgzVlV",
        "outputId": "4a2459f7-63b6-450a-dd8a-99539a4804f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "                A            B         C         D\n",
            "0    Sales Report      Q4 2024    Region     North\n",
            "1         Product        Units     Price     Count\n",
            "2          Laptop          150     $1200         5\n",
            "3           Phone          200      $800         8\n",
            "4           Notes      Details     Extra      Misc\n",
            "5           Notes      Details     Extra      Misc\n",
            "6           Notes      Details     Extra      Misc\n",
            "7           Notes      Details     Extra      Misc\n",
            "8           Notes      Details     Extra      Misc\n",
            "9           Notes      Details     Extra      Misc\n",
            "10          Notes      Details     Extra      Misc\n",
            "11          Notes      Details     Extra      Misc\n",
            "12  Employee List   Department  Location  Building\n",
            "13           Name  Engineering   Seattle         A\n",
            "14     John Smith  Engineering   Seattle         A\n",
            "15       Jane Doe    Marketing  New York         B\n",
            "16        Summary         Info      More       End\n",
            "17        Summary         Info      More       End\n",
            "18        Summary         Info      More       End\n",
            "19        Summary         Info      More       End\n",
            "20        Summary         Info      More       End\n",
            "21        Summary         Info      More       End\n",
            "22        Summary         Info      More       End\n",
            "23        Summary         Info      More       End\n",
            "24    Q4 Finances       Target    Status   Quarter\n",
            "25        Revenue       Actual  Goal Met        Q4\n",
            "26         $10000       $12000       Yes  Complete\n",
            "27         $15000       $14000       Yes  Complete\n",
            "\n",
            "Structural Anchor Extraction Results:\n",
            "  Original shape: (28, 4) (112 cells)\n",
            "  Skeleton shape: (16, 4) (64 cells)\n",
            "  Compression ratio: 1.75x\n",
            "  Space saved: 42.9%\n",
            "\n",
            "Extracted Structural Skeleton:\n",
            "                A            B         C         D\n",
            "0    Sales Report      Q4 2024    Region     North\n",
            "1         Product        Units     Price     Count\n",
            "2          Laptop          150     $1200         5\n",
            "3           Phone          200      $800         8\n",
            "4           Notes      Details     Extra      Misc\n",
            "11          Notes      Details     Extra      Misc\n",
            "12  Employee List   Department  Location  Building\n",
            "13           Name  Engineering   Seattle         A\n",
            "14     John Smith  Engineering   Seattle         A\n",
            "15       Jane Doe    Marketing  New York         B\n",
            "16        Summary         Info      More       End\n",
            "23        Summary         Info      More       End\n",
            "24    Q4 Finances       Target    Status   Quarter\n",
            "25        Revenue       Actual  Goal Met        Q4\n",
            "26         $10000       $12000       Yes  Complete\n",
            "27         $15000       $14000       Yes  Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm preserved table boundaries and structural anchors while removing\n",
        "distant homogeneous regions that don't contribute to layout understanding.\n"
      ],
      "metadata": {
        "id": "eFnTjzMezyKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "Structural Anchor Extraction Results:\n",
        "  Original shape: (28, 4) (112 cells)\n",
        "  Skeleton shape: (16, 4) (64 cells)\n",
        "  Compression ratio: 1.75x\n",
        "  Space saved: 42.9%\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "tmm7zHMozgtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Patameter 'k' Demonstration"
      ],
      "metadata": {
        "id": "tZlRPU6Bz32Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameter 'k' controls how many rows to keep around each structural anchor.\n",
        "Lower k = more aggressive compression, Higher k = preserve more context"
      ],
      "metadata": {
        "id": "izlZM99d0B6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k_val in [0, 1, 2]:\n",
        "    test_skeleton = extract_structural_skeleton(df, k=k_val)\n",
        "    compression = (df.shape[0] * df.shape[1]) / (test_skeleton.shape[0] * test_skeleton.shape[1])\n",
        "    space_saved = ((df.shape[0] * df.shape[1] - test_skeleton.shape[0] * test_skeleton.shape[1]) / (df.shape[0] * df.shape[1]) * 100)\n",
        "    print(f\"k={k_val}: {df.shape} -> {test_skeleton.shape}, compression: {compression:.2f}x, space saved: {space_saved:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpuJ4ZLF0Fh8",
        "outputId": "ef67d931-bb39-4745-b0ce-21c1e6b43df6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k=0: (28, 4) -> (12, 4), compression: 2.33x, space saved: 57.1%\n",
            "k=1: (28, 4) -> (16, 4), compression: 1.75x, space saved: 42.9%\n",
            "k=2: (28, 4) -> (20, 4), compression: 1.40x, space saved: 28.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "k=0: (28, 4) -> (12, 4), compression: 2.33x, space saved: 57.1%\n",
        "k=1: (28, 4) -> (16, 4), compression: 1.75x, space saved: 42.9%\n",
        "k=2: (28, 4) -> (20, 4), compression: 1.40x, space saved: 28.6%\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pCBshr1H0Ibk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. INVERTED INDEX TRANSLATION DEMONSTRATION"
      ],
      "metadata": {
        "id": "mmaqrs0V2CXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm implementation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xsQ-6Drn3-Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "\n",
        "def create_cell_address(row, col, df):\n",
        "    \"\"\"Convert row, col indices to Excel-style address like 'A1', 'B2', etc.\"\"\"\n",
        "    return f'{df.columns[col]}{row + 1}'\n",
        "\n",
        "def merge_cell_ranges(addresses):\n",
        "    \"\"\"\n",
        "    Merge consecutive cell addresses into ranges like A1:A4, B5:B7, etc.\n",
        "    \"\"\"\n",
        "    if not addresses:\n",
        "        return \"\"\n",
        "\n",
        "    # Parse addresses into (column, row) tuples\n",
        "    parsed = []\n",
        "    for addr in addresses:\n",
        "        col = addr[0]  # Assume single letter column for simplicity\n",
        "        row = int(addr[1:])\n",
        "        parsed.append((col, row, addr))\n",
        "\n",
        "    # Sort by column then row\n",
        "    parsed.sort()\n",
        "\n",
        "    ranges = []\n",
        "    current_range_start = None\n",
        "    current_range_end = None\n",
        "    current_col = None\n",
        "\n",
        "    for col, row, addr in parsed:\n",
        "        if current_col != col:\n",
        "            # New column, finish previous range\n",
        "            if current_range_start:\n",
        "                if current_range_start == current_range_end:\n",
        "                    ranges.append(current_range_start)\n",
        "                else:\n",
        "                    ranges.append(f\"{current_range_start}:{current_range_end}\")\n",
        "\n",
        "            # Start new range\n",
        "            current_col = col\n",
        "            current_range_start = addr\n",
        "            current_range_end = addr\n",
        "        else:\n",
        "            # Same column, check if consecutive\n",
        "            prev_row = int(current_range_end[1:])\n",
        "            if row == prev_row + 1:\n",
        "                # Consecutive, extend range\n",
        "                current_range_end = addr\n",
        "            else:\n",
        "                # Not consecutive, finish current range and start new one\n",
        "                if current_range_start == current_range_end:\n",
        "                    ranges.append(current_range_start)\n",
        "                else:\n",
        "                    ranges.append(f\"{current_range_start}:{current_range_end}\")\n",
        "                current_range_start = addr\n",
        "                current_range_end = addr\n",
        "\n",
        "    # Finish last range\n",
        "    if current_range_start:\n",
        "        if current_range_start == current_range_end:\n",
        "            ranges.append(current_range_start)\n",
        "        else:\n",
        "            ranges.append(f\"{current_range_start}:{current_range_end}\")\n",
        "\n",
        "    return ','.join(ranges)\n",
        "\n",
        "def invert_index_with_ranges(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Create inverted index with proper range merging .\n",
        "    Maps values to cell address ranges (e.g., \"$100\": \"A1:A4\", \"$150\": \"B5,B7\")\n",
        "    \"\"\"\n",
        "    index = defaultdict(list)\n",
        "\n",
        "    # Build value-to-addresses mapping\n",
        "    for r, c in itertools.product(range(df.shape[0]), range(df.shape[1])):\n",
        "        val = df.iat[r, c]\n",
        "        if pd.notna(val) and str(val).strip() != '':\n",
        "            addr = create_cell_address(r, c, df)\n",
        "            index[str(val)].append(addr)\n",
        "\n",
        "    # Merge addresses into ranges\n",
        "    result = {}\n",
        "    for val, addrs in index.items():\n",
        "        result[val] = merge_cell_ranges(addrs)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "zF3Neuqk4Da5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of traditional row-by-row serialization, this method creates a\n",
        "value-to-address dictionary that:\n",
        "- Maps identical cell values to their address ranges\n",
        "- Eliminates redundant encoding of repeated values\n",
        "- Merges consecutive addresses into ranges (e.g., A1:A4)\n",
        "- Skips empty cells entirely"
      ],
      "metadata": {
        "id": "pCuiFsR92Umi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a realistic spreadsheet with repeated values that demonstrates the technique:"
      ],
      "metadata": {
        "id": "vhPZogIv2Wwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"EXAMPLE: Financial Report with Repeated Values\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Create sample data with intentional repetitions to show the benefit\n",
        "data = {\n",
        "    'A': ['Quarter', 'Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2', '', 'Total', '$500K', '$500K'],\n",
        "    'B': ['Product', 'Laptop', 'Laptop', 'Desktop', 'Laptop', 'Desktop', 'Desktop', '', 'Revenue', '$300K', '$200K'],\n",
        "    'C': ['Revenue', '$100K', '$150K', '$100K', '$200K', '$100K', '$150K', '', 'Target', 'Met', 'Met'],\n",
        "    'D': ['Status', 'Active', 'Active', 'Pending', 'Active', 'Pending', 'Active', '', 'Goal', 'Yes', 'Yes'],\n",
        "    'E': ['Region', 'North', 'North', 'South', 'North', 'South', 'South', '', '', '', '']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"ORIGINAL SPREADSHEET:\")\n",
        "print(\"Shape:\", df.shape, f\"({df.shape[0] * df.shape[1]} cells)\")\n",
        "print()\n",
        "# Add row numbers for reference\n",
        "df_display = df.copy()\n",
        "df_display.index = [f'Row {i+1}' for i in range(len(df))]\n",
        "print(df_display)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEh7F7kE2lpS",
        "outputId": "3b434d56-0631-4e05-f88e-8080f9b1886a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "EXAMPLE: Financial Report with Repeated Values\n",
            "------------------------------------------------------------\n",
            "ORIGINAL SPREADSHEET:\n",
            "Shape: (11, 5) (55 cells)\n",
            "\n",
            "              A        B        C        D       E\n",
            "Row 1   Quarter  Product  Revenue   Status  Region\n",
            "Row 2        Q1   Laptop    $100K   Active   North\n",
            "Row 3        Q1   Laptop    $150K   Active   North\n",
            "Row 4        Q1  Desktop    $100K  Pending   South\n",
            "Row 5        Q2   Laptop    $200K   Active   North\n",
            "Row 6        Q2  Desktop    $100K  Pending   South\n",
            "Row 7        Q2  Desktop    $150K   Active   South\n",
            "Row 8                                             \n",
            "Row 9     Total  Revenue   Target     Goal        \n",
            "Row 10    $500K    $300K      Met      Yes        \n",
            "Row 11    $500K    $200K      Met      Yes        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "ORIGINAL SPREADSHEET:\n",
        "Shape: (11, 5) (55 cells)\n",
        "\n",
        "              A        B        C        D       E\n",
        "Row 1   Quarter  Product  Revenue   Status  Region\n",
        "Row 2        Q1   Laptop    $100K   Active   North\n",
        "Row 3        Q1   Laptop    $150K   Active   North\n",
        "Row 4        Q1  Desktop    $100K  Pending   South\n",
        "Row 5        Q2   Laptop    $200K   Active   North\n",
        "Row 6        Q2  Desktop    $100K  Pending   South\n",
        "Row 7        Q2  Desktop    $150K   Active   South\n",
        "Row 8\n",
        "Row 9     Total  Revenue   Target     Goal\n",
        "Row 10    $500K    $300K      Met      Yes\n",
        "Row 11    $500K    $200K      Met      Yes\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "gCwlcGBK2sAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traditional Encoding (Row-by-Row):"
      ],
      "metadata": {
        "id": "mS4wq6oM25C7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This would encode every cell individually:"
      ],
      "metadata": {
        "id": "t9Oya1V-2-Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"TRADITIONAL ENCODING (Row-by-Row):\")\n",
        "print(\"-\" * 60)\n",
        "token_count = 0\n",
        "for r in range(df.shape[0]):\n",
        "    for c in range(df.shape[1]):\n",
        "        val = df.iat[r, c]\n",
        "        addr = create_cell_address(r, c, df)\n",
        "        if pd.notna(val) and str(val).strip():\n",
        "            print(f\"  {addr}: '{val}'\")\n",
        "            token_count += 1\n",
        "        elif str(val).strip() == '':\n",
        "            print(f\"  {addr}: ''\")  # Empty cells still need to be encoded\n",
        "            token_count += 1\n",
        "\n",
        "print(f\"\\nTraditional method tokens: {token_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC_yQ6Ia27Ov",
        "outputId": "db9f9705-b2f4-4dbe-8a39-77d0e09d3f85"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "TRADITIONAL ENCODING (Row-by-Row):\n",
            "------------------------------------------------------------\n",
            "  A1: 'Quarter'\n",
            "  B1: 'Product'\n",
            "  C1: 'Revenue'\n",
            "  D1: 'Status'\n",
            "  E1: 'Region'\n",
            "  A2: 'Q1'\n",
            "  B2: 'Laptop'\n",
            "  C2: '$100K'\n",
            "  D2: 'Active'\n",
            "  E2: 'North'\n",
            "  A3: 'Q1'\n",
            "  B3: 'Laptop'\n",
            "  C3: '$150K'\n",
            "  D3: 'Active'\n",
            "  E3: 'North'\n",
            "  A4: 'Q1'\n",
            "  B4: 'Desktop'\n",
            "  C4: '$100K'\n",
            "  D4: 'Pending'\n",
            "  E4: 'South'\n",
            "  A5: 'Q2'\n",
            "  B5: 'Laptop'\n",
            "  C5: '$200K'\n",
            "  D5: 'Active'\n",
            "  E5: 'North'\n",
            "  A6: 'Q2'\n",
            "  B6: 'Desktop'\n",
            "  C6: '$100K'\n",
            "  D6: 'Pending'\n",
            "  E6: 'South'\n",
            "  A7: 'Q2'\n",
            "  B7: 'Desktop'\n",
            "  C7: '$150K'\n",
            "  D7: 'Active'\n",
            "  E7: 'South'\n",
            "  A8: ''\n",
            "  B8: ''\n",
            "  C8: ''\n",
            "  D8: ''\n",
            "  E8: ''\n",
            "  A9: 'Total'\n",
            "  B9: 'Revenue'\n",
            "  C9: 'Target'\n",
            "  D9: 'Goal'\n",
            "  E9: ''\n",
            "  A10: '$500K'\n",
            "  B10: '$300K'\n",
            "  C10: 'Met'\n",
            "  D10: 'Yes'\n",
            "  E10: ''\n",
            "  A11: '$500K'\n",
            "  B11: '$200K'\n",
            "  C11: 'Met'\n",
            "  D11: 'Yes'\n",
            "  E11: ''\n",
            "\n",
            "Traditional method tokens: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Traditional method tokens: 55\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-9SzMDLd3EIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inverted Index Translation:"
      ],
      "metadata": {
        "id": "bjZ6UK7o3KJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"INVERTED INDEX TRANSLATION:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Apply inverted index\n",
        "inverted = invert_index_with_ranges(df)\n",
        "\n",
        "print(\"Value-to-Address Range Mapping:\")\n",
        "print(\"(Empty cells excluded, ranges merged where possible)\")\n",
        "print()\n",
        "\n",
        "# Sort by value for better readability\n",
        "for val in sorted(inverted.keys()):\n",
        "    ranges = inverted[val]\n",
        "    print(f\"  '{val}': {ranges}\")\n",
        "\n",
        "print(f\"\\nInverted index entries: {len(inverted)}\")\n",
        "print(f\"Token reduction: {token_count} -> {len(inverted)} ({(token_count - len(inverted))/token_count*100:.1f}% reduction)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRjLF1wg3TAv",
        "outputId": "dc4a572f-6b61-49a0-876d-59b5ac1e1623"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "INVERTED INDEX TRANSLATION:\n",
            "------------------------------------------------------------\n",
            "Value-to-Address Range Mapping:\n",
            "(Empty cells excluded, ranges merged where possible)\n",
            "\n",
            "  '$100K': C2,C4,C6\n",
            "  '$150K': C3,C7\n",
            "  '$200K': B11,C5\n",
            "  '$300K': B10\n",
            "  '$500K': A10:A11\n",
            "  'Active': D2:D3,D5,D7\n",
            "  'Desktop': B4,B6:B7\n",
            "  'Goal': D9\n",
            "  'Laptop': B2:B3,B5\n",
            "  'Met': C10:C11\n",
            "  'North': E2:E3,E5\n",
            "  'Pending': D4,D6\n",
            "  'Product': B1\n",
            "  'Q1': A2:A4\n",
            "  'Q2': A5:A7\n",
            "  'Quarter': A1\n",
            "  'Region': E1\n",
            "  'Revenue': B9,C1\n",
            "  'South': E4,E6:E7\n",
            "  'Status': D1\n",
            "  'Target': C9\n",
            "  'Total': A9\n",
            "  'Yes': D10:D11\n",
            "\n",
            "Inverted index entries: 23\n",
            "Token reduction: 55 -> 23 (58.2% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token reduction: 55 -> 23 (58.2% reduction)"
      ],
      "metadata": {
        "id": "fRu7hkAy3d8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Benifits Demonstrated:"
      ],
      "metadata": {
        "id": "76Vks0g23h4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. REDUNDANCY ELIMINATION:\n",
        "   - 'Q1' appears 3 times -> mapped once to 'A2:A4'\n",
        "   - '$100K' appears 3 times -> mapped once to 'C2,C4,C6'\n",
        "   - 'Active' appears 4 times -> mapped to ranges\n",
        "\n",
        "2. RANGE MERGING:\n",
        "   - Consecutive cells with same value become ranges\n",
        "   - 'Q1' in A2,A3,A4 becomes 'A2:A4'\n",
        "   - 'Q1' in A2,A3,A4 becomes 'A2:A4'\n",
        "   - Non-consecutive cells stay separate: 'C2,C4,C6'\n",
        "\n",
        "3. EMPTY CELL ELIMINATION:\n",
        "   - Empty cells in column E and row 8 are completely skipped\n",
        "   - No wasted tokens on encoding empty positions\n",
        "\n",
        "4. LOSSLESS COMPRESSION:\n",
        "   - All non-empty data is preserved\n",
        "   - Exact cell positions are maintained\n",
        "   - Can be perfectly reconstructed\n",
        "\n",
        "   - 'Q1' in A2,A3,A4 becomes 'A2:A4'\n",
        "   - Non-consecutive cells stay separate: 'C2,C4,C6'"
      ],
      "metadata": {
        "id": "FfOtoCOZ3tzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This technique significantly reduces token usage while preserving\n",
        "all structural and content information needed for LLM processing."
      ],
      "metadata": {
        "id": "t7f_67023z8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. DATA FORMAT AGGREGATION"
      ],
      "metadata": {
        "id": "99HnvhsVOFCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technique Description:\n",
        "Instead of encoding exact numerical values, this method:\n",
        "- Groups cells by their data format/type (dates, currencies, percentages, etc.)\n",
        "- Uses rule-based recognition for 9 predefined types:\n",
        "  Year, Integer, Float, Percentage, Scientific notation, Date, Time, Currency, Email, Others\n",
        "- Preserves semantic meaning while reducing token usage"
      ],
      "metadata": {
        "id": "fyUlVvv6OJxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm implementation"
      ],
      "metadata": {
        "id": "GjuMY8fBPfWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "def create_rule_based_recognizer():\n",
        "    \"\"\"\n",
        "    Create rule-based recognizer for predefined data types:\n",
        "    Year, Integer, Float, Percentage, Scientific notation, Date, Time, Currency, Email, and Others\n",
        "    \"\"\"\n",
        "\n",
        "    def recognize_data_type(value):\n",
        "        \"\"\"Recognize data type based on cell value using rules\"\"\"\n",
        "        if pd.isna(value) or str(value).strip() == '':\n",
        "            return 'Empty'\n",
        "\n",
        "        value_str = str(value).strip()\n",
        "\n",
        "        # Year (4-digit number between reasonable range)\n",
        "        if re.match(r'^(19|20|21)\\d{2}$', value_str):\n",
        "            return 'Year'\n",
        "\n",
        "        # Email\n",
        "        if re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$', value_str):\n",
        "            return 'Email'\n",
        "\n",
        "        # Percentage (ends with %)\n",
        "        if re.match(r'^-?\\d+\\.?\\d*%$', value_str):\n",
        "            return 'Percentage'\n",
        "\n",
        "        # Currency (starts with currency symbol)\n",
        "        if re.match(r'^[\\$£€¥₹]\\s*-?\\d{1,3}(,\\d{3})*(\\.\\d{2})?$', value_str):\n",
        "            return 'Currency'\n",
        "\n",
        "        # Scientific notation\n",
        "        if re.match(r'^-?\\d+\\.?\\d*[eE][+-]?\\d+$', value_str):\n",
        "            return 'ScientificNotation'\n",
        "\n",
        "        # Date (various formats)\n",
        "        date_patterns = [\n",
        "            r'^\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}$',  # YYYY-MM-DD or YYYY/MM/DD\n",
        "            r'^\\d{1,2}[-/]\\d{1,2}[-/]\\d{4}$',  # MM-DD-YYYY or MM/DD/YYYY\n",
        "            r'^\\d{1,2}[-/]\\d{1,2}[-/]\\d{2}$',  # MM-DD-YY or MM/DD/YY\n",
        "        ]\n",
        "        for pattern in date_patterns:\n",
        "            if re.match(pattern, value_str):\n",
        "                return 'Date'\n",
        "\n",
        "        # Time (HH:MM or HH:MM:SS)\n",
        "        if re.match(r'^\\d{1,2}:\\d{2}(:\\d{2})?(\\s*(AM|PM))?$', value_str, re.IGNORECASE):\n",
        "            return 'Time'\n",
        "\n",
        "        # Float (decimal number)\n",
        "        if re.match(r'^-?\\d+\\.\\d+$', value_str):\n",
        "            return 'Float'\n",
        "\n",
        "        # Integer (whole number)\n",
        "        if re.match(r'^-?\\d+$', value_str):\n",
        "            return 'Integer'\n",
        "\n",
        "        # Others (everything else)\n",
        "        return 'Others'\n",
        "\n",
        "    return recognize_data_type\n",
        "\n",
        "def aggregate_by_data_format(df):\n",
        "    \"\"\"\n",
        "    Aggregate cells by data format using rule-based recognition\n",
        "    \"\"\"\n",
        "    recognizer = create_rule_based_recognizer()\n",
        "\n",
        "    # Analyze each cell using rule-based recognition\n",
        "    rule_groups = defaultdict(list)\n",
        "\n",
        "    for i in range(df.shape[0]):\n",
        "        for j in range(df.shape[1]):\n",
        "            value = df.iat[i, j]\n",
        "            cell_addr = f\"{df.columns[j]}{i+1}\"\n",
        "\n",
        "            # Rule-based data type recognition\n",
        "            data_type = recognizer(value)\n",
        "            rule_groups[data_type].append({\n",
        "                'address': cell_addr,\n",
        "                'value': value,\n",
        "                'type': data_type\n",
        "            })\n",
        "\n",
        "    return rule_groups"
      ],
      "metadata": {
        "id": "gfSRtDN1O_Cv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample data"
      ],
      "metadata": {
        "id": "oVJcmVPBPz0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a sample DataFrame with various data types for demonstration"
      ],
      "metadata": {
        "id": "4h_sVn4JP-kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data with different data types\n",
        "data = {\n",
        "    'Category': ['Date', 'Date', 'Time', 'Time', 'Currency', 'Currency',\n",
        "                'Percentage', 'Percentage', 'Integer', 'Integer', 'Float',\n",
        "                'Float', 'Scientific', 'Year', 'Email', 'Phone', 'Text'],\n",
        "    'Value': ['2024-01-15', '01/15/2024', '14:30:00', '2:30 PM', '$1,234.56',\n",
        "              '£9,876.54', '75%', '12.5%', '42', '1000', '3.14159', '2.718',\n",
        "              '6.022e23', '2024', 'user@example.com', '+1-555-123-4567', 'Hello World'],\n",
        "    'Description': ['ISO Date Format', 'US Date Format', '24-hour Time',\n",
        "                    '12-hour Time', 'US Dollar', 'British Pound', 'Percentage',\n",
        "                    'Percentage (decimal)', 'Whole Number', 'Thousand',\n",
        "                    'Pi (5 decimals)', 'e (3 decimals)', 'Avogadro Number',\n",
        "                    'Year Format', 'Email Address', 'Phone Number', 'Text String']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(f\"DataFrame shape: {df.shape}\")\n",
        "print(\"\\nSample data:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5mRONBbP18q",
        "outputId": "005813d4-9416-4959-83a7-8a2c411e8648"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame shape: (17, 3)\n",
            "\n",
            "Sample data:\n",
            "      Category             Value           Description\n",
            "0         Date        2024-01-15       ISO Date Format\n",
            "1         Date        01/15/2024        US Date Format\n",
            "2         Time          14:30:00          24-hour Time\n",
            "3         Time           2:30 PM          12-hour Time\n",
            "4     Currency         $1,234.56             US Dollar\n",
            "5     Currency         £9,876.54         British Pound\n",
            "6   Percentage               75%            Percentage\n",
            "7   Percentage             12.5%  Percentage (decimal)\n",
            "8      Integer                42          Whole Number\n",
            "9      Integer              1000              Thousand\n",
            "10       Float           3.14159       Pi (5 decimals)\n",
            "11       Float             2.718        e (3 decimals)\n",
            "12  Scientific          6.022e23       Avogadro Number\n",
            "13        Year              2024           Year Format\n",
            "14       Email  user@example.com         Email Address\n",
            "15       Phone   +1-555-123-4567          Phone Number\n",
            "16        Text       Hello World           Text String\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traditional Encoding (Every Value Individually)"
      ],
      "metadata": {
        "id": "SMs9iBLUQESo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"TRADITIONAL ENCODING (Every Value Individually)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Count original tokens (each cell encoded separately)\n",
        "total_cells = 0\n",
        "non_empty_cells = 0\n",
        "for i in range(df.shape[0]):\n",
        "    for j in range(df.shape[1]):\n",
        "        total_cells += 1\n",
        "        if pd.notna(df.iat[i, j]) and str(df.iat[i, j]).strip():\n",
        "            non_empty_cells += 1\n",
        "            cell_addr = f\"{df.columns[j]}{i+1}\"\n",
        "            print(f\"  {cell_addr}: '{df.iat[i, j]}'\")\n",
        "\n",
        "print(f\"\\nTraditional encoding tokens: {non_empty_cells}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0CaXYRZQY3D",
        "outputId": "353e9436-7ee2-4e04-c0f0-bf8151f8aff5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "TRADITIONAL ENCODING (Every Value Individually)\n",
            "------------------------------------------------------------\n",
            "  Category1: 'Date'\n",
            "  Value1: '2024-01-15'\n",
            "  Description1: 'ISO Date Format'\n",
            "  Category2: 'Date'\n",
            "  Value2: '01/15/2024'\n",
            "  Description2: 'US Date Format'\n",
            "  Category3: 'Time'\n",
            "  Value3: '14:30:00'\n",
            "  Description3: '24-hour Time'\n",
            "  Category4: 'Time'\n",
            "  Value4: '2:30 PM'\n",
            "  Description4: '12-hour Time'\n",
            "  Category5: 'Currency'\n",
            "  Value5: '$1,234.56'\n",
            "  Description5: 'US Dollar'\n",
            "  Category6: 'Currency'\n",
            "  Value6: '£9,876.54'\n",
            "  Description6: 'British Pound'\n",
            "  Category7: 'Percentage'\n",
            "  Value7: '75%'\n",
            "  Description7: 'Percentage'\n",
            "  Category8: 'Percentage'\n",
            "  Value8: '12.5%'\n",
            "  Description8: 'Percentage (decimal)'\n",
            "  Category9: 'Integer'\n",
            "  Value9: '42'\n",
            "  Description9: 'Whole Number'\n",
            "  Category10: 'Integer'\n",
            "  Value10: '1000'\n",
            "  Description10: 'Thousand'\n",
            "  Category11: 'Float'\n",
            "  Value11: '3.14159'\n",
            "  Description11: 'Pi (5 decimals)'\n",
            "  Category12: 'Float'\n",
            "  Value12: '2.718'\n",
            "  Description12: 'e (3 decimals)'\n",
            "  Category13: 'Scientific'\n",
            "  Value13: '6.022e23'\n",
            "  Description13: 'Avogadro Number'\n",
            "  Category14: 'Year'\n",
            "  Value14: '2024'\n",
            "  Description14: 'Year Format'\n",
            "  Category15: 'Email'\n",
            "  Value15: 'user@example.com'\n",
            "  Description15: 'Email Address'\n",
            "  Category16: 'Phone'\n",
            "  Value16: '+1-555-123-4567'\n",
            "  Description16: 'Phone Number'\n",
            "  Category17: 'Text'\n",
            "  Value17: 'Hello World'\n",
            "  Description17: 'Text String'\n",
            "\n",
            "Traditional encoding tokens: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traditional encoding tokens: 51"
      ],
      "metadata": {
        "id": "LAmoyfhMQgXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule-based Data Type Aggregation"
      ],
      "metadata": {
        "id": "xhLjItaIQls2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform aggregation analysis\n",
        "rule_groups = aggregate_by_data_format(df)\n",
        "\n",
        "print(\"RULE-BASED DATA TYPE AGGREGATION:\")\n",
        "print(\"(Using predefined recognition patterns for 9 data types)\")\n",
        "for data_type, cells in sorted(rule_groups.items()):\n",
        "    if data_type != 'Empty' and cells:\n",
        "        addresses = [cell['address'] for cell in cells]\n",
        "        sample_values = [str(cell['value']) for cell in cells[:3]]  # Show first 3 values\n",
        "        sample_text = ', '.join(sample_values)\n",
        "        if len(cells) > 3:\n",
        "            sample_text += '...'\n",
        "        print(f\"   Type '{data_type}': {','.join(addresses)} (values: {sample_text})\")\n",
        "\n",
        "# Calculate compression\n",
        "unique_types = len([group for group in rule_groups.values() if group and group[0]['type'] != 'Empty'])\n",
        "\n",
        "compression_ratio = non_empty_cells / unique_types if unique_types > 0 else 1\n",
        "space_saved = ((non_empty_cells - unique_types) / non_empty_cells * 100) if non_empty_cells > 0 else 0\n",
        "\n",
        "print(f\"\\nCOMPRESSION RESULTS:\")\n",
        "print(f\"   Original tokens: {non_empty_cells}\")\n",
        "print(f\"   Aggregated types: {unique_types}\")\n",
        "print(f\"   Compression ratio: {compression_ratio:.2f}x\")\n",
        "print(f\"   Space saved: {space_saved:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OamGJM_Qy_7",
        "outputId": "3cd6c66d-9167-49bb-b766-90c054a0e348"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RULE-BASED DATA TYPE AGGREGATION:\n",
            "(Using predefined recognition patterns for 9 data types)\n",
            "   Type 'Currency': Value5,Value6 (values: $1,234.56, £9,876.54)\n",
            "   Type 'Date': Value1,Value2 (values: 2024-01-15, 01/15/2024)\n",
            "   Type 'Email': Value15 (values: user@example.com)\n",
            "   Type 'Float': Value11,Value12 (values: 3.14159, 2.718)\n",
            "   Type 'Integer': Value9,Value10 (values: 42, 1000)\n",
            "   Type 'Others': Category1,Description1,Category2,Description2,Category3,Description3,Category4,Description4,Category5,Description5,Category6,Description6,Category7,Description7,Category8,Description8,Category9,Description9,Category10,Description10,Category11,Description11,Category12,Description12,Category13,Description13,Category14,Description14,Category15,Description15,Category16,Value16,Description16,Category17,Value17,Description17 (values: Date, ISO Date Format, Date...)\n",
            "   Type 'Percentage': Value7,Value8 (values: 75%, 12.5%)\n",
            "   Type 'ScientificNotation': Value13 (values: 6.022e23)\n",
            "   Type 'Time': Value3,Value4 (values: 14:30:00, 2:30 PM)\n",
            "   Type 'Year': Value14 (values: 2024)\n",
            "\n",
            "COMPRESSION RESULTS:\n",
            "   Original tokens: 51\n",
            "   Aggregated types: 10\n",
            "   Compression ratio: 5.10x\n",
            "   Space saved: 80.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "COMPRESSION RESULTS:\n",
        "   Original tokens: 51\n",
        "   Aggregated types: 10\n",
        "   Compression ratio: 5.10x\n",
        "   Space saved: 80.4%\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HjyPhYuSQ2Yb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Benifits Demonstrated:"
      ],
      "metadata": {
        "id": "bnNM_482Q-wz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. SEMANTIC PRESERVATION:\n",
        "   - Values '2024-01-15' and '01/15/2024' both recognized as 'Date'\n",
        "   - Different currencies ($1234.56, £9876.54) grouped as 'Currency'\n",
        "   - Various percentages (75%, 12.5%) unified as 'Percentage'\n",
        "\n",
        "2. INTELLIGENT TYPE RECOGNITION:\n",
        "   - Rule-based recognizer covers 9 common data types\n",
        "   - Patterns detect semantic meaning (dates, currencies, emails, etc.)\n",
        "   - Fallback to 'Others' for unrecognized patterns\n",
        "\n",
        "3. STRUCTURE UNDERSTANDING:\n",
        "   - Preserves data type semantics without exact values\n",
        "   - Enables LLMs to understand column purposes and data patterns\n",
        "   - Maintains enough information for structural analysis\n",
        "\n",
        "4. TOKEN EFFICIENCY:\n",
        "   - Dramatic reduction in tokens while preserving meaning\n",
        "   - Groups cells by semantic type rather than exact content\n",
        "   - Significant compression with minimal information loss"
      ],
      "metadata": {
        "id": "HDuuemd5RB_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This technique enables LLMs to understand spreadsheet data types and structure without being overwhelmed by exact numerical values."
      ],
      "metadata": {
        "id": "LGXC_mmbRDYA"
      }
    }
  ]
}